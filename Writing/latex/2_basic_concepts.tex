\section{Basic Concepts}
	\subsection{Machine Learning}
		A sub-branch of computer science that rose to prominence and started evolving during the 1950s as part of research in the field of artificial intelligence. Machine learning refers the development of algorithms, which allow computers to learn from presented examples. The computer is thereafter supposed to learn from its collected experience and automate the process of solving similar tasks. This process is referred to by term \textit{training}.
		\\~\\
		One official definition as coined by Tom M. Mitchell \cite{mitchell} is  "A computer program is said to learn from experience $E$ with respect to some class of tasks $ T $ and performance measure $ P $ if its performance at tasks in $ T $, as measured by $ P $, improves with experience $ E $."
		\\~\\
		The most common use of machine learning algorithms is the analysis of real-world data for certain tasks, when a concrete programmer-written application would be ineffective in solving. Such is the case for example with problems, which a human would be able to solve, but would not be able to determine the rules for solving explicitly. Or alternatively, where the rules are not constant, but rather evolving as time progresses. The purpose of teaching a machine to solve such tasks, is modelling, prediction or detection of details or certainties about the real world. 
		\\~\\
		Vivid examples of real world uses are speech recognition as used in cellphones or in 
		call routing system as well as visual recognition, where and algorithm is trained to recognize graphic patterns and used in medicine or in hand written text recognition.
	\subsection{Text Mining}
		Text mining refers to the practice of extracting facts out of raw meta-data, which comes in the form of text corpora or other unstructured data. Initially the data must be structured into a form compatible for its statistical analysis. This includes but not limited to, segmenting the text to more basic building blocks such as paragraphs or sentences. This practice is known as \textbf{stemming}. Cleaning up the data by removing non-informative words, which serve a grammatical role in human language, but tend to be of no use for language processing done by machines. In the next phase the words are normalized to their \textbf{stem} by removing inflection which modifies the word's tense, case number and other grammatical properties. In the professional nomenclature, this is referred to as \textbf{stemming} or \textbf{lemmatizing}.
		\\~\\
		Methods used in text mining involve statistical pattern recognition,tagging-annotation, information extraction and frequency analysis. The end goal of text mining is namely, the production of qualitative information out of raw text, often automatically using machine learning.
		\\~\\
		Most of the usage of text mining methods in this work will be with the use of the NLTK module for the Python programming language. NLTK is a suite of libraries developed in the Department of Computer and Information Science at the University of Pennsylvania for Natural Language Processing \cite{nltk_book}.
		
		{\color{red} \Large citation needed}
		
	\subsection{Unstructured data}
		{\color{red} \Large placeholder}
		
	\subsection{Classification}
		{\color{red} \Large placeholder}
		
	\subsection{Information Quality}
		{\color{red} \Large placeholder}
