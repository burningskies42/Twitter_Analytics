\section{Methodology}
	The approach I undertake in this study is similar to previous works in the field. Initially, data is gathered on a given theme. In case of this research, the main query to be studied would regard Tweets relating to the subject of E-Commerce platforms. The captured data, must then be restructured to fit the data-model of this study, namely appropriate input for Machine Learning algorithms. This includes removing incomplete observations and building \textit{features}\footnote{\label{ml_note}Machine Learning nomenclature}. \textit{Features} are unique properties of the data, which are used to describe it. These features are then analyzed for consistency and correctness. Subsequently, the features are passed into different Machine Learning algorithms, in order to \textit{train}\footnotemark[1] them. Afterwards, the empirical success of these different algorithms will be statistically measured the summarized. Additionally, implications are to be drawn about other use-cases, which are out of the scope of this research. 
	
	The study consists of gathering raw data in the form of Tweets originating from the Twitter databases. To make the data more closely resemble a live stream of Information on Tweeter, the data was collected as it was intercepted in the servers. The STREAMING API is usually implemented is such use-cases. Using the STREAMING API, a connection is established to the servers, which captures Tweets relevant (containing) a given search term. 
	
	
	