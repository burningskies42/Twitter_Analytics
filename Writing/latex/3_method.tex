\section{Methodology}
	The approach undertaken in this study is similar to previous works in the field of applied Machine Learning. Initially, a main theme of the content is selected according to the quality and volume it might produce. In the case of this research, the direction of inquiry is concerned with Tweets relating to the subject of E-Commerce platforms. Such platforms usually see an abundance of Tweets fulfilling the volume requirement. However, additional cleaning steps are taken to insure the informations quality. These cleaning measures are elaborated in the \hyperref[Application]{Application chapter}.
	
	\par
	
	On of the main motives of this research is to observe whether social media data can be evaluated in real-time and distilled into practical knowledge. With this consideration in mind, the data used in this work should bear as much resemblance as possible to a live Tweeter data stream. Acknowledging this consideration, the raw data in the form of Tweets in gathered from the Twitter databases. Namely, the data is collected synchronously, as it is intercepted by the servers. The \textit{Streaming Application Programming Interface} (\cite{stream_api}) is implemented for such use-cases. Employing the \textit{Streaming} API, a connection is established to the servers, which captures a narrow stream (about 15\%) of all Tweets relevant to a given search term. The reduction of stream is due to the complexity in both sending and receiving such a volume of data. Twitter also offers a full non-reduced access through their proprietary \textit{Firehose} API.
	
	\par
	
	The captured data, must then be restructured to fit the data-model of this study, specifically input appropriated for Machine Learning purposes. This includes a preliminary analysis of the data and removal of incomplete observations. The JSON data structure in which Tweets are stored allows for a dynamic non-standard structure, which in turn translates to non-standardized data. Consequently, Tweets must be adapted to conform to a unitary pattern, usually by \textit{flattening} the data into a table. It is also common for Tweets to retrospectively be removed from the Tweeter servers, either by their owners or by Twitter moderators. Such Tweets cannot be analyzed after the fact, since they are no longer available on-line. The process of gathering data and cleansing it is discussed in \hyperref[sec:collect_data]{Part [4.1]}.
	
	\newpage
	
	The next stage entails restructuring the raw captured Tweets into datasets. For this purpose, \textit{features}\footnote{\label{ml_note}Machine Learning nomenclature} are extracted from each observation and converted to a standard array, representing the original Tweet. \textit{Features} are unique properties of the data, which describe it and also possibly its owner, dependent on the approach. Different types of \textit{Features} are used in accordance with the Learning approach undertaken. These approaches are further discussed in \hyperref[build_features]{Part [4.2]}.
	
	\par
	
	The previously constructed features are ensuingly analyzed for consistency and correctness. Subsequently, the features are passed into various Machine Learning algorithms, with the purpose of \textit{training}\footnotemark[1] classifiers. \textit{Training} is the process of deducing the decision rules for classifying the data into one of the categories. This deduction is based on the information the algorithm draws from the input data. Afterwards, the empirical success of these different algorithms will be statistically measured and summarized. Additionally, implications are to be drawn about other use-cases. The classification task observed here is subjective or \textit{fuzzy}\footnote{Fuzzy Logic: A system of logic in which statements do not have to be entirely true or false - \textit{Merriam-Webster Dictionary}} in nature, since the labels themselves are abstract and arguable. Success in this experiment could prove that similarly subjective classification projects are practical. 
	
	\subsection{Training Classifier}
	The purpose of \textit{training} is to create Classifiers. A Classifier is a function, which is fed new observations and automatically recognizes and \textit{labels}\footnotemark[1] them. The intrinsic decision algorithm, through which the Classifier will decide how to allocate a novel observation, usually remains hidden and operates as a black-box of sorts. Seeing that the decision rules could be numerous and considerably not intuitive for human readers, they remain unrevealed. Particularly so, when said algorithms are convolutional. Convolutional Machine Learning schemes, such as \hyperref[ann]{Deep Neural Networks}, may incorporate numerous stages of parameter construction layer-upon-layer, which renders them practically incomprehensible to human users. The actual implementation of all the algorithms would be programmed in the Python programming language and will primarily make use of the scikit-learn module by \cite{scikit-learn}.
	
	\par
	
	The data used for the purpose of this study consolidates 12.520 unique Tweets. Different approaches vary in the percentage of the data used from this corpus. In order to insure robust results, the \textit{Hold-out Method} is used across the board. For each instance of \textit{training} the data is split into two parts - a \textit{training} set and testing set. The \textit{training set} would usually be allocated the larger portion of the data (between 60\% and 90\%) and would be used, as the name suggests for training the classifiers. The remaining corpus chunk (between 10\% and 40\%) would be used for testing the classifiers success. Before each such training-testing session, the data corpus is shuffled. This in turn means, that the training and testing sets constantly differ. This process of splitting, training and testing using different data in each iteration should produce statistically significant results. This method of constantly splitting the data randomly ensures the results robustness.
	
	\par
	
	The following paragraphs expand on the different Machine Learning schemes. Figure \ref{fig:classifier_matrix} illustrates these schemes with relation to computational complexity and their interoperability.
	
	\begin{figure}[h]
		\centering
		%\includegraphics[width=0.8\textwidth]{methods}
		\scalebox{1.0}{\input{images/methods.eps_tex}}
		\captionsetup{width=0.8\textwidth}
		\caption{Clustering of Different Classifiers}
		\label{fig:classifier_matrix}
	\end{figure}
	
	\subsection{Supervised Learning}
	\label{classifer_types}
	
	\input{regressions}
	\input{naive_bayes}
	\input{svm}
	\input{ann}
	\input{trees}

	
	
	
	
	
	
	
	
	
	
	
	
		
	