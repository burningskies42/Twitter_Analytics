\section{Results}
	In the section the classification that took place will be analyzed. The classification were conducted in different configurations of  dataset size and number of features. For optimization purposes other characteristics will be discussed such as robustness of the results as well as training and classification time.
	
	\subsection{Grouping of Classifiers}
		The classifiers were grouped into 5 general groups. Additionally, a Vote Classifier, tallying the voted classifications was observed. The groupings were done according to the base algorithm of each classifier. This organization schema is demonstrated in table \ref{table:class_grps}.
		
		\begin{table}[h]	
			\begin{center}
				\begin{tabular}{l | l} 
					\hline
					\hline
					\multicolumn{1}{c|}{\multirow{2}{*}{Group Name}} & \multicolumn{1}{|c}{\multirow{2}{*}{Classifiers}}\\ 
					 &   \\ 
					\hline
					Regressions 	  & Logistic Regression*  \\
					\hline
					Naive Bayes       & Simple NB, Bernoulli NB, Multinomial NB \\
					\hline
					\vspace*{-1mm} 
					Supports Vector   & Linea Kernel, Radial Basis Function Kernel,\\
					Machines		  & Polynomial Kernel, Sigmoid Kernel \\
					\hline
					\vspace*{-1mm} 
					Artificial Neural & Multi-Layer Percpetron,  \\
					Networks		  & Stochastic Gradient Descent** \\
					\hline
					Ensemble Methods  & Random Forest, Adaptive Boosting \\
					\hline\hline
					\multicolumn{2}{p{1\textwidth}}{ \footnotesize * Note that Logistic Regression refers to a classification schema using logistic distribution for possible values of the fore-casted class, rather then an actual regression. Furthermore, Logistic Regression is a simplistic classifier and is demonstrated as a benchmark measure, rather then an actual classifier.} \\
					\multicolumn{2}{p{1\textwidth}}{ \footnotesize ** Refers to Neural Networks which make use of SGD to minimize their cost function by gradually reducing the error terms} \\
				\end{tabular}	
			\end{center}
			\caption[Classifier Groupings]{Classifier Groupings}
			\label{table:class_grps}
		\end{table}
	
		In the upcoming results analysis the name scheme used in table \ref{table:class_grps} will refer to average values inside each such named group. 
	
	\subsection{Descriptive Statistics}
		I conducted the labeling in the process of several weeks. The labeling process was very subjective. Apart from holding up to a few rules of thumb, it is hard to formally model the labeling pattern. This in fact, makes this an ideal task for Machine Learning, since the logic behind it is intuitive rather than strict.
		
		\subsubsection{Data Size and Labels}
			The initial data set consisted of about 12 thousand labeled Tweets captured during a period of several days. The software would launch a listener, which would intercept all Tweets containing the word \textit{Amazon}. The listener was also programmed to ignore all Tweets which contain one of the following words and Expressions: \textit{gift}, \textit{giftcard}, \textit{giveaway}. These phrases were usually found in spam Tweets or Tweets posted by Bots and contained mostly advertising content. The captured Tweets were than labeled manually using custom made software. Out of the 12 thousand Tweets, about 1400 were labeled as "News" and the rest as "Not-News". These ratio between interesting and not-interesting content make practical sense as well, since we strive to boil the data down to only the most subjectively essential information. 
			
			\par
			
			Another issue with the data was trending topics. It was common for an announcement to be made about a new product or service, which would result in a major percentage of all Amazon related traffic to concentrate around the topic. For example, this was the case with the Amazon Echo device. For unclear purposes, some bots would take such an announcement Tweet, which originated from a certified publisher, and retweet it numerous times with minor adjustments to the text. This is turn, escalates the problem of the data being prone to concentrate heavily on some topics and much less on others. A classifier trained on such data is prone to overfitting.
			
			\paragraph{Overfitting}
				Overfitting is a very common issue in the classification field. this means that a classifier is trained in a matter fitting the data very specifically. Therefore, any slight deviation in the new data from the rigid constraints of the trained classifier results in misclassifications. Overfitting could also be viewed as the inability of the algorithm to generalize the rules learned from the data onto new information, which in essence is the purpose of Machine Learning Classification. To prevent this phenomena, the data should he heterogeneous in its content and properties and present as many different learning scenarios for the algorithm to learn from. Overall, overfitting is accepted to some degree in classification, since it is impossible to completely eliminate it. The alternative to overfitting is \textit{underfitting}, which means an algorithm which over simplifies and generalizes to an extent which makes classifications useless.
		
		\subsubsection{Number of Features}
			Initially, the classification simulation were conducted with the goal of reaching the most precise classifier irregardless of cost and duration. Thereby, the largest possible data set was used with 5000 features, when implementing the Bag-of-Words or N-Grams approach. The number of features, thus indicates the amount of sought-after words of expressions. Naturally, having more features results in more precise classifiers but at the same time incurs higher computational costs. Furthermore, the greater the training data set is, the more words must be scanned and tabulated by the algorithm, which also has an increasing effect on the computational time. An additional not obvious disadvantage to training classifiers with a large number of features is the risk of overfitting the classifier, as discussed previously. \\
			
			
			\begin{table}[h]
				\hskip-0.4cm
				\footnotesize	
					\begin{tabular}{c| c c c c c c c c} 
						\hline \hline
						 Number & \multicolumn{8}{c}{Dataset Size} \\
						 \cline{2-9}
						 of Features & 100 &  200 &  300  & 500  & 1000 & 1500 & 2000 & 2800\\ 
						\hline
						\vspace*{-2mm} 
						\multirow{2}{*}{100} & 1,07  & 2,06  & 3,09 	& 4,96  & 9,96  & 14,98 & 19,92 & 29,16  \\
										  	 &(2,68) & (5,27)&(7,91)	&(12,83)&(25,94)&(39,08)&(52,05)&(76)    \\
						\vspace*{-2mm} 
						\multirow{2}{*}{500} & 1,18  & 2,25  & 3,40 	&	5,46& 10,98 & 16,49 & 22,23 & 31,23  \\
						 	      			 & (2,79)& (5,47)&(8,31)	&(13,35)&(27,05)&(40,79)&(54,83)&(77,36) \\
						\vspace*{-2mm} 
						\multirow{2}{*}{1000}& 1,32  & 2,50	 & 3,86 	& 6,09 	& 12,23 & 18,38 & 25,70 & 35,33  \\
							      			 & (2,92)& (5,73)&(8,79)	&(14,01)&(28,42)&(42,96)&(59,1) &(82,67) \\
						\vspace*{-2mm} 
						\multirow{2}{*}{3000}& 2,01	 & 4,21  & 5,45	    & 9,04  & 18,06 & 26,79 & 37,94 & 52,60  \\
							     			 &(3,5)  &(7,28) &(10,35)   &(16,7) &(34,27)&(51,94)&(72,49)&(101,72)\\
						\vspace*{-2mm} 
						\multirow{2}{*}{5000}& 2,40	 & 5,68	 & 6,96	    & 11,90 & 24,13 & 36,10 &50,12	& 91,61   \\
							      			 & (3,88)&(8,95) &(11,92)   &(19,68)&(40,68)&(62,27)&(85,98)&(272,76)\\
						\hline
						\hline
					\end{tabular}
				\caption[Classifier Duration]{Classifier Training Duration}
				\label{table:class_duration}
			\end{table}
		
		Table \ref{table:class_duration} demonstrates the average duration in seconds to train a classifier, with the training dataset size denoted on the horizontal axis and the number of identifying features on the vertical axis. Notice the large standard errors, indicated by the numbers in brackets. This strong variation is due to the differences in training time . For example, an average classifier with 3000 features and 
				
			
			
	
	\subsection{Success Measures}
	
		\subsubsection{Accuracy}
		
		\subsubsection{Cohens Kappa}
		
		\subsubsection{Confusion Matrix}
		
		\subsubsection{Receiver operating characteristic}
	
	\subsection{Approaches}
	
		\subsubsection{Descriptive Features}
		
		\subsubsection{Bag of Words}
		
		\subsubsection{N-Grams}




	{\color{red} \Large Place holder} \\
	\hyperref{http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/}{category}{name}{
		- NOTE: Random Forest is not suitable for Bag-Of-Words because of sparse data
	}
	