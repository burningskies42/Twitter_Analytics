\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Motivation}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Current State of Research}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Possible Difficulties}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Research Question}{section.1}% 5
\BOOKMARK [1][-]{section.2}{Basic Concepts}{}% 6
\BOOKMARK [2][-]{subsection.2.1}{Machine Learning}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.2}{Text Mining}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.3}{Unstructured Data}{section.2}% 9
\BOOKMARK [2][-]{subsection.2.4}{Classification}{section.2}% 10
\BOOKMARK [2][-]{subsection.2.5}{Information Quality}{section.2}% 11
\BOOKMARK [1][-]{section.3}{Methodology}{}% 12
\BOOKMARK [2][-]{subsection.3.1}{Training Classifier}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.2}{Supervised Learning}{section.3}% 14
\BOOKMARK [3][-]{subsubsection.3.2.1}{Regressions}{subsection.3.2}% 15
\BOOKMARK [3][-]{subsubsection.3.2.2}{Naive Bayes}{subsection.3.2}% 16
\BOOKMARK [3][-]{subsubsection.3.2.3}{Support Vector Machines}{subsection.3.2}% 17
\BOOKMARK [3][-]{subsubsection.3.2.4}{Artificial Neural Networks}{subsection.3.2}% 18
\BOOKMARK [3][-]{subsubsection.3.2.5}{Decision Trees and Random Forests}{subsection.3.2}% 19
\BOOKMARK [1][-]{section.4}{Application}{}% 20
\BOOKMARK [2][-]{subsection.4.1}{Information Procurement}{section.4}% 21
\BOOKMARK [2][-]{subsection.4.2}{Data cleansing}{section.4}% 22
\BOOKMARK [2][-]{subsection.4.3}{Building Feature-Sets}{section.4}% 23
\BOOKMARK [3][-]{subsubsection.4.3.1}{Descriptive Features}{subsection.4.3}% 24
\BOOKMARK [3][-]{subsubsection.4.3.2}{Bag-of-Words}{subsection.4.3}% 25
\BOOKMARK [3][-]{subsubsection.4.3.3}{N-Grams}{subsection.4.3}% 26
\BOOKMARK [2][-]{subsection.4.4}{Labeling the Training Data}{section.4}% 27
\BOOKMARK [2][-]{subsection.4.5}{Training Classifiers}{section.4}% 28
\BOOKMARK [1][-]{section.5}{Results and Discussion}{}% 29
\BOOKMARK [2][-]{subsection.5.1}{Grouping of Classifiers}{section.5}% 30
\BOOKMARK [2][-]{subsection.5.2}{Descriptive Statistics}{section.5}% 31
\BOOKMARK [3][-]{subsubsection.5.2.1}{Data Size and Labels}{subsection.5.2}% 32
\BOOKMARK [3][-]{subsubsection.5.2.2}{Weighted Dataset}{subsection.5.2}% 33
\BOOKMARK [3][-]{subsubsection.5.2.3}{Overfitting}{subsection.5.2}% 34
\BOOKMARK [3][-]{subsubsection.5.2.4}{Data Sparsity}{subsection.5.2}% 35
\BOOKMARK [3][-]{subsubsection.5.2.5}{Number of Features}{subsection.5.2}% 36
\BOOKMARK [2][-]{subsection.5.3}{Success Measures}{section.5}% 37
\BOOKMARK [3][-]{subsubsection.5.3.1}{Accuracy}{subsection.5.3}% 38
\BOOKMARK [3][-]{subsubsection.5.3.2}{Cohens Kappa}{subsection.5.3}% 39
\BOOKMARK [3][-]{subsubsection.5.3.3}{Confusion Matrix}{subsection.5.3}% 40
\BOOKMARK [3][-]{subsubsection.5.3.4}{Receiver Operating Characteristic}{subsection.5.3}% 41
\BOOKMARK [1][-]{section.6}{Conclusion}{}% 42
\BOOKMARK [2][-]{subsection.6.1}{Theory and Practice}{section.6}% 43
\BOOKMARK [2][-]{subsection.6.2}{Strengths and Weaknesses}{section.6}% 44
\BOOKMARK [2][-]{subsection.6.3}{Future Research}{section.6}% 45
\BOOKMARK [1][-]{section*.78}{Appendices}{}% 46
\BOOKMARK [2][-]{subsection.1..1}{Training Duration per Algorithm}{section*.78}% 47
\BOOKMARK [2][-]{subsection.1..2}{Stop Words}{section*.78}% 48
\BOOKMARK [2][-]{subsection.1..3}{Descriptive Features General Statistics}{section*.78}% 49
